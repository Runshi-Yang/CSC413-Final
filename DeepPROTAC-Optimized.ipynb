{"cells":[{"cell_type":"markdown","metadata":{"id":"1QMadWMVPRBQ"},"source":["## CSC413 - research project\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQjoo0J4PWxb"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/DeepPROTACs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6sb0x60PXCH"},"outputs":[],"source":["! pip install torch\n","! pip install torch_geometric\n","! pip install rdkit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYX6OjxAP7ZJ"},"outputs":[],"source":["import sys\n","import numpy as np\n","import torch\n","import os\n","import pickle\n","import logging\n","from pathlib import  Path\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from protacloader import PROTACSet, collater\n","from model_Runshi import GraphConv, SmilesNet, ProtacModel\n","from train_and_test4 import train\n","from prepare_data import GraphData"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jAWTA0piBKu"},"outputs":[],"source":["BATCH_SIZE = 1\n","EPOCH = 200\n","TRAIN_RATE = 0.8\n","LEARNING_RATE = 0.0005\n","WEIGHT_DECAY = 0.0001\n","TRAIN_NAME = \"test_test\"\n","for handler in logging.root.handlers[:]:\n","      logging.root.removeHandler(handler)\n","logging.basicConfig(filename=\"/content/drive/MyDrive/DeepPROTACs/log/\"+TRAIN_NAME+\".log\", filemode=\"a\", level=logging.DEBUG, force=True)\n","logging.getLogger('RootLogger').setLevel(logging.DEBUG)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TpUq-OIIjMGB"},"outputs":[],"source":["Path('/content/drive/MyDrive/DeepPROTACs/log').mkdir(exist_ok=True)\n","Path('/content/drive/MyDrive/DeepPROTACs/model').mkdir(exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QuA-n0_EjOR-"},"outputs":[],"source":["def main_small():\n","  root = \"small_dataset/data\"\n","  ligase_ligand = GraphData(\"ligase_ligand\", root)\n","  ligase_pocket = GraphData(\"ligase_pocket\", root)\n","  target_ligand = GraphData(\"target_ligand\", root)\n","  target_pocket = GraphData(\"target_pocket\", root)\n","  with open(os.path.join(target_pocket.processed_dir, \"smiles.pkl\"),\"rb\") as f:\n","      smiles = pickle.load(f)\n","  with open('small_dataset/name.pkl','rb') as f:\n","      name_list = pickle.load(f)\n","  label = torch.load(os.path.join(target_pocket.processed_dir, \"label.pt\"))\n","\n","  protac_set = PROTACSet(\n","      name_list,\n","      ligase_ligand, \n","      ligase_pocket, \n","      target_ligand, \n","      target_pocket, \n","      smiles, \n","      label,\n","  )\n","  data_size = len(protac_set)\n","  train_size = int(data_size * TRAIN_RATE)\n","  test_size = data_size - train_size\n","  logging.info(f\"all data: {data_size}\")\n","  logging.info(f\"train data: {train_size}\")\n","  logging.info(f\"test data: {test_size}\")\n","  train_dataset = torch.utils.data.Subset(protac_set, range(train_size))\n","  test_dataset = torch.utils.data.Subset(protac_set, range(train_size, data_size))\n","  trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collater,drop_last=False, shuffle=True)\n","  testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collater,drop_last=False)\n","\n","  ligase_ligand_model = GraphConv(num_embeddings=10)\n","  ligase_pocket_model = GraphConv(num_embeddings=5)\n","  target_ligand_model = GraphConv(num_embeddings=10)\n","  target_pocket_model = GraphConv(num_embeddings=5)\n","  smiles_model = SmilesNet(batch_size=BATCH_SIZE)\n","  model = ProtacModel(\n","      ligase_ligand_model, \n","      ligase_pocket_model,\n","      target_ligand_model,\n","      target_pocket_model,\n","      smiles_model,\n","  )\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  writer = SummaryWriter(f'runs/{TRAIN_NAME}')\n","  model = train(\n","      model, \n","      train_loader=trainloader, \n","      valid_loader=testloader,\n","      device=device,\n","      writer=writer,\n","      LOSS_NAME=TRAIN_NAME,\n","      batch_size=BATCH_SIZE,\n","      epoch=EPOCH,\n","      lr=LEARNING_RATE,\n","      weight_decay = WEIGHT_DECAY\n","  )\n","  for handler in logging.root.handlers[:]:\n","      logging.root.removeHandler(handler)\n","\n","def main_large():\n","  root = \"large_dataset/data\"\n","  with open('large_dataset/name.pkl','rb') as f:\n","        name_list = pickle.load(f)\n","  data_size = len(name_list)/2\n","  train_size = int(data_size * TRAIN_RATE)\n","  test_size = data_size - train_size\n","\n","  train_ligase_ligand = GraphData(\"ligase_ligand\", root)[:train_size] + GraphData(\"ligase_ligand\", root)[949:949+train_size]\n","  test_ligase_ligand = GraphData(\"ligase_ligand\", root)[train_size:949] + GraphData(\"ligase_ligand\", root)[949+train_size:]\n","  train_ligase_pocket = GraphData(\"ligase_pocket\", root)[:train_size] + GraphData(\"ligase_pocket\", root)[949:949+train_size]\n","  test_ligase_pocket = GraphData(\"ligase_pocket\", root)[train_size:949] + GraphData(\"ligase_pocket\", root)[949+train_size:]\n","  train_target_ligand = GraphData(\"target_ligand\", root)[:train_size] + GraphData(\"target_ligand\", root)[949:949+train_size]\n","  test_target_ligand = GraphData(\"target_ligand\", root)[train_size:949] + GraphData(\"target_ligand\", root)[949+train_size:]\n","  train_target_pocket = GraphData(\"target_pocket\", root)[:train_size] + GraphData(\"target_pocket\", root)[949:949+train_size]\n","  test_target_pocket = GraphData(\"target_pocket\", root)[train_size:949] + GraphData(\"target_pocket\", root)[949+train_size:]\n","  with open(root+\"/processed/smiles.pkl\",\"rb\") as f:\n","        smiles = pickle.load(f)\n","  train_smiles = smiles[:train_size] + smiles[949:949+train_size]\n","  test_smiles = smiles[train_size:949] + smiles[949+train_size:]\n","\n","  with open('large_dataset/name.pkl','rb') as f:\n","        name_list = pickle.load(f)\n","  train_name = name_list[:train_size] + name_list[949:949+train_size]\n","  test_name = name_list[train_size:949] + name_list[949+train_size:]\n","\n","  label = torch.load(root+\"/processed/label.pt\")\n","  train_label = label[:train_size] + label[949:949+train_size]\n","  test_label = label[train_size:949] + label[949+train_size:]\n","\n","  train_set = PROTACSet(\n","    train_name,\n","    train_ligase_ligand, \n","    train_ligase_pocket, \n","    train_target_ligand, \n","    train_target_pocket, \n","    train_smiles, \n","    train_label,\n","  )\n","\n","  valid_set = PROTACSet(\n","    test_name,\n","    test_ligase_ligand, \n","    test_ligase_pocket, \n","    test_target_ligand, \n","    test_target_pocket, \n","    test_smiles, \n","    test_label,\n","  )\n","\n","  data_size = len(train_set) + len(valid_set)\n","  train_size = len(train_set)\n","  test_size = len(valid_set)\n","  logging.info(f\"all data: {data_size}\")\n","  logging.info(f\"train data: {train_size}\")\n","  logging.info(f\"test data: {test_size}\")\n","  trainloader = DataLoader(train_set, batch_size=BATCH_SIZE, collate_fn=collater,drop_last=False, shuffle=True)\n","  testloader = DataLoader(valid_set, batch_size=BATCH_SIZE, collate_fn=collater,drop_last=False, shuffle=True)\n","\n","  ligase_ligand_model = GraphConv(num_embeddings=10)\n","  ligase_pocket_model = GraphConv(num_embeddings=5)\n","  target_ligand_model = GraphConv(num_embeddings=10)\n","  target_pocket_model = GraphConv(num_embeddings=5)\n","  smiles_model = SmilesNet(batch_size=BATCH_SIZE)\n","  model = ProtacModel(\n","      ligase_ligand_model, \n","      ligase_pocket_model,\n","      target_ligand_model,\n","      target_pocket_model,\n","      smiles_model,\n","  )\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  writer = SummaryWriter(f'runs/{TRAIN_NAME}')\n","  model = train(\n","      model, \n","      train_loader=trainloader, \n","      valid_loader=testloader,\n","      device=device,\n","      writer=writer,\n","      LOSS_NAME=TRAIN_NAME,\n","      batch_size=BATCH_SIZE,\n","      epoch=EPOCH,\n","      lr=LEARNING_RATE,\n","      weight_decay = WEIGHT_DECAY\n","  )\n","  for handler in logging.root.handlers[:]:\n","      logging.root.removeHandler(handler)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqZRgaRJjSPj","executionInfo":{"status":"error","timestamp":1681865097911,"user_tz":240,"elapsed":18446,"user":{"displayName":"Evianne Rovers","userId":"00902404549160504394"}},"colab":{"base_uri":"https://localhost:8080/","height":384},"outputId":"d66c789b-1335-406a-ea85-10928420543c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch_geometric/utils/scatter.py:93: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n","  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-b9fac2dbbd85>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#comment out which one you DON'T want to run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#main_small()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmain_large\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-18-585d99be955a>\u001b[0m in \u001b[0;36mmain_large\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'runs/{TRAIN_NAME}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m   model = train(\n\u001b[0m\u001b[1;32m    136\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m       \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1_2em3v0TLxpcrRipRJlWxC6PKaqk5biD/DeepPROTACs/train_and_test4.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, lr, epoch, weight_decay, train_loader, valid_loader, device, writer, LOSS_NAME, batch_size)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#comment out which one you DON'T want to run\n","#main_small()\n","main_large()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QBzEObmmjTXz"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"Z4N4knSb-YRZ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}